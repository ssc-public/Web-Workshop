<!-- language-all: lang-js -->

<div align="center">
تهیه‌کنندگان:
محمد خلفی، علیرضا فرشی، ابوالفضل قلندری
</div>

<br>

<div dir = 'rtl' style='text-align:justify'>

# چرا کافکا
در ابتدای تحقیق میخواهیم خود کافکا و دلیل استفاده از آن را شرح دهیم.
فرض کنید شما یک سیستم منبع ( source system) و یک سیستم مقصد ( target system ) در اختیار دارید. به عنوان مثال سیستم مبدا شما میتواند وب سایت شما، کلاینت ایمیل شما یا هر چیز دیگری باشد و سیستم مقصد شما میتواند پایگاه داده های مختلف باشند. حال هدف آن است که دیتا را از سیستم های مبدا خود در درون سیستم های مقصد ذخیره سازی کنیم که این کار خیلی پیچیده خواهد بود زیرا باید هرکدام از سیستم های منبع را با هریک از سیستم های مقصد integrate کنیم که هر integration دردسرهایی از جمله پروتکل مربوط به خود و اینکه ممکن است امن هم نباشد را دارد و در حالت بسیار ساده اگر به عنوان مثال ۶ سیستم مبدا و ۵ سیستم مقصد داشته باشیم طبق اصل ضرب ۳۰ integration باید انجام شود که طبق شکل زیر یک نمونه از آن را مشاهده میکنید.

<img src="images\img1.png" alt="img1"> 

حال برای حل این مشکل کافکا به میدان آمد. در واقع کافکا جریان های داده را جدا میکند. همان طور که در شکل زیر مشخص است سیستم های منبع که در بالای شکل قرار گرفتند هریک از آنها مستقل از دیگری داده‌ی خود را روی کافکا منتشر میکنند و سرویس های مقصد که در پایین شکل قرار گرفتند داده‌های مورد نیاز خود را از کافکا برمیدارند. نکته مثبت اینجا این است که سرویس های مقصد به تمام داده های سرویس های منبع دسترسی دارند.

<img src="images\img2.png" alt="img2"> 

## کمی اطلاعات عمومی درباره کافکا

- کافکا برای اولین بار توسط لینکدین ایجاد شد و در حال حاضر بیش از 2000 شرکت از آن استفاده می کنند که به عنوان چند نمونه میتوان netflix , airBnB, yahoo, walmart و ... را اشاره کرد.
- کافکا از دید افقی قابل اسکیل می باشد.بدین معنا که میتوان چند سرور به صورت همزمان به آن اضافه کرد و آن ها را اسکیل کرد بنابرین یک سیستم distributed می باشد.
- کارایی کفکا بسیار بالاست به طوری که تاخیر آن کمتر از 10 میلی ثانیه میباشد.

##چند نمونه از کابرد های کافکا
- سیستم پیام رسانی
- ردیابی فعالیت
- جمع آوری معیار ها برای موقعیت های مختلف
- پردازش جریان
حال به آشنایی بیشتر با کافکا می پردازیم که در واقع آن را به دو بخش تقسیم می کنیم در بخش اول با مقدمان و مفاهیم اولیه موجود در کافکا و در بخش دوم با kafka connect آشنا می شویم.

## مفاهیم اولیه در کافکا
### topic
یک جریانی از داده در کافکا می باشد. همان طور که در پایگاه داده ها ما جداولی برای ذخیره سازی داده های داریم مشابه آن topic در کافکا می باشد. محدودیتی در داشتن تعداد topic برای کافکا نداریم و topic های موجود در کافکا با نام خود شناسایی می شوند بنابرین نام هایشان باید یکتا باشد.

### partition 
هر topic به چند partition تقسیم می شود که هر پارتیشن به صورت مرتب شده از 0 تا هر عددی شماره گذاری می شود. پیام یا داده های ما در درون یک پارتیشن قرار می گیرند و هنگام قرارگیری یک id افرایشی دریافت می کنند که مشخص می کند در کجای پارتیشن داده ما درح شده است که به این id, offset گفته می شود که در شکل توضیحات مربوطه می توان مشاهده کرد.

<img src="images\img3.png" alt="img3"> 
<br/>

### offset
که در صفحه قبل تعریف شد فقط برای یک پارتیشن خاص دارای معناست بدین معنا که به عنوان مثال offset 3 در پارتیشن های مختلف بیانگر داده‌های مختلف است.

داده ها به صورت موقت در درون پارتیشن ها قرار می گیرند که به صورت دیفالت دو هفته می باشند و پس از دو هفته از بین می روند و این داده ها قابلیت تغییر یا ویرایش ندارند و فقط قابلیت خوانده شدن دارند تا مورد استفاده قرار بگیرند. توجه شود که داده ها هنگام ذخیره شده روی کافکا روی یک پارتیشن رندوم قرار می گیرند مگر اینکه یک کلیدی برای آن در نظر گرفته شود که در ادامه بیشتر درباره این موضوع صحبت خواهیم کرد.

همان طور که ما میتوانیم تعداد دلخواهی تاپیک در کافکا داشته باشیم میتوان تعداد دلخواهی پارتیشن در تاپیک داشت.

### broker

یک خوشه کافکا را میتوان به چند سرور تقسیم‌بندی کرد که به هر‌کدام از آن سرور‌ها broker گفته می‌شود. هر broker با یک id قابل شناسایی می‌باشد و می‌توان تعدادی تاپیک به آن اختصاص داد. نکته جالب توجه در این خصوص این است که اگر ما به هرکدام از این broker ها متصل شویم به تمام خوشه کافکا متصل شده ایم و به کل خوشه کافکا دسترسی داریم. معمولا تعداد broker های یک خوشه کافکا ۳ تا می‌باشد اما خوشه‌های بزرگتر میتوانند بیش از ۱۰۰ broker نیز داشته باشند.
حال در شکل زیر میتوان به صورت شهودی مشاهده کرد که ما  ۳ broker ۲ تاپیک و تاپیک اول سه تا پارتیشن و تاپیک دوم دوتا پارتیشن دارد و روی broker ها قرار گرفته‌اند.

<img src="images\img4.png" alt="img4"> 
<br/>


### topic replication factor

فرض کنید هر پارتیشن از یک تاپیک فقط روی یکی از broker ها موجود باشد. در اینصورت اگر یکی از broker ها مشکلی برایش پیش آمد و قطع شد داده‌ ما نیز از بین می‌رود. بنابراین اینجا مفهومی به نام topic replication  مطرح می‌شود که ما معمولا دو یا سه نسخه از یک پارتیشن را روی broker‌ های مختلف قرار می‌دهیم تا در صورت بروز این مشکل، داده ما حفظ شود. در شکل زیر می توان در حالتی ساده این را مشاهده کرد.

<img src="images\img5.png" alt="img5"> 
<br/>


### leader
حال که یک پارتیشن ممکن است روی چند broker موجود باشد در هر زمان ما یکی از broker های مربوط به آن پارتیشن را به عنوان لیدر انتخاب میکنیم که این لیدر وظیفه دریافت دیتا یا serve کردن دیتا را به عهده دارد و بقیه نسخه‌ها فقط داده را سنکرون می‌کنند. مطابق شکل زیر می‌توان لیدر بودن را با توجه به علامت ستاره مشاهده کرد.


<img src="images\img6.png" alt="img6"> 
<br/>

### producer
حال که دیدیم داده‌ها روی تاپیک در کافکا ذخیره می‌شوند سوالی که پیش می‌آید این است که داده از کجا به درون این تاپیک‌ها می‌آیند که جواب این سوال producer می‌باشد. producer در واقع می‌توان گفت همان سرویس‌های منبع ما هستند که داده را روی کافکا بارگذاری می‌کنند. برای اینکه این‌ کار را انجام دهند کافی است نام تاپیک و یک broker ای که میخواهند به آن متصل شوند را مشخص کنند و خود کافکا به صورت اتوماتیک فرایند بارگذاری داده را هندل می‌کند. در شکل زیر نمای کلی را مشاده میکنید.

<img src="images\img7.png" alt="img7"> 
<br/>

حال هنگامی که producer داده‌ای را ارسال می‌کند برای گرفتن تاییدیه دریافت داده توسط کافکا با سه حالت روبه‌رو میشود :


1. Acks = 0 : در این حالت producer منتظر دریافت تاییدیه از طرف کافکا نمی‌ماند که فایده آن این است که می‌توان در مدت زمان کوتاهی داده‌های زیاید را بارگذاری کرد اما ضرر آن این است که ممکن است دیتای ما از بین برود.

2. Acks = 1 : در این حالت producer منتظر دریافت تاییدیه فقط از طرف leader می‌ماند و خب این مورد بر خلاف مورد قبل اطمینان داریم که داده ما در حداقل یکی از broker‌ ها موجود است و کل داده ما از بین نمیرود اما از طرفی یک مدت زمان کوتاهی باید صرف تایید شود.

3. Acks = all : در این حالت producer نه تنها منتظر تایید از طرف leader بلکه منتظر تایید از طرف replica ها نیز می‌ماند و در اینجا هیچ داده‌ای از ما از بین نخواهد رفت و مدت زمان منتظر ماندن نیز از دو حالت دیگر بیشتر خواهد بود.


### message keys
در قبل گفتیم که داده‌ها برای قرارگیری روی کافکا، روی یک پارتیشن رندوم قرار میگیرند اما producer می‌تواند به همراه آن داده یک id نیز با پیام بفرستد که در صورت ارسال id تضمین می‌شود داده‌های با کلید یکسان در یک پارتیشن قرار می‌گیرند.


### consumer
هنگامی که داده روی کافکا قرار بگیرد یک نفر باید داده‌ها را بخواند که به آن consumer گفته می‌شود. در واقع consumer همان سیستم‌های مقصد می‌باشند. برای خواندن داده کافی است نام تاپیک و یک broker را برای وصل شدن مشخص کند و کافکا به صورت اتوماتیک داده را برای consumer می‌آورد. شکل زیر به صورت کلی این فرایند را نشان می‌دهد.
حال با توجه به این شکل consumer داده را از پارتیشن‌های ۰ و ۱ به صورت هم‌زمان و در هر پارتیشن با شروع از ایندکس صفر به صورت ترتیبی می‌خواند.


### consumer groups
برای بهبود فرایند موازی‌سازی از این مفهوم استفاده می‌کنیم به طوری که هر Consumer داده را به صورت group می‌خواند. هر consumer در درون یک گروه میتواند از پارتیشن هایی که consumer ای تا الان به آن اساین نشده است داده بخواند. بدیهی است که نباید تعداد consumer‌ ها بیشتر از تعداد پارتیشن‌ها باشند زیرا در غیر اینصورت consumer های بیکار خواهیم داشت. در شکل زیر group هایی با تعداد consumer‌ های متفاوت را مشاهده می‌کنید.


<img src="images\img8.png" alt="img8"> 
<br/>

### consumer offsets
هنگامی که consumer در حال خواندن داده از کافکا می‌باشد فرض کنیدتا یک ایندکسی این خواندن را انجام داده است. اگر بخواهد ادامه این خواندن را انجام دهد باید آدرس ایندکسی که تا الان خوانده است را بداند که کافکا این کار را هندل می‌کند. در واقع به صورت لایو کافکا ایندکس‌هایی که consumer تا الان خوانده را در یک تاپیک به نام consumer offsets ذخیره میکند و هنگامی که بخواهد ادامه دهد از آنجا استفاده می‌کند.


## kafka connect
حال به سراغ بخش دوم که آشنایی با کافکا کانکت می‌باشد می‌رویم. اگر به تاریخچه کافکا یک نگاهی بیندازیم در سال ۲۰۱۵ برای اولین بار در ورژن نهم کافکا، کافکا کانکت به آن اضافه شد.
دلیل به‌وجود آمدن این مفهوم این بود که ما در هنگام استفاده ازکافکا ۳ نوع ارتباط داریم :

1. ارتباط منبع با کافکا
2. ارتباط کافکا با کافکا: هنگاهی که می خواهیم روی داده خود در کافکا پردازش انجام داده و نتیجه را دوباره همان جا ذخیره کنیم از این مورد استفاده می کنیم.
3. ارتباط با کافکا با سرویس مقصد

در موارد ۱ و ۳ هنگام اتصال کافکا با سرویس‌های منبع و مقصد پیچیدگی‌هایی وجود دارد که کافکا کانکت انجام این اتصال را برای ما ساده کرد. در واقع این ارتباط‌هایی که بیان شد کاربرد زیادی هم دارند. برنامه‌نویس‌ها همواره به دنبال این هستند که داده‌ای را از یک منبع یکسان دریافت و آن را به یک منبع مقصد یکسان ارسال کنند که کافکا کانکت این کار را راحت می‌کند.


### معماری kafka connect

<img src="images\img9.png" alt="img9"> 
<br/>

همان طور که از شکل مشخص است ، بین منابع مقصد و منبع و کافکا یک سرویسی به نام connect cluster وجود دارد که در درون آن یک سری worker موجود است که این worker ها با گرفتن یک connector داده‌ها را از منبع به کافکا و یا از کافکا به مقصد منتقل می‌کنند.
حال به بررسی مفاهیم موجود در کافکا کانکت می‌پردازیم. کافکا کانکت از تعدادی connector تشکیل شده است که هرکدام از این connector ها یک کد اجرا شده‌ی جاوا می‌باشند. در دنیا تعداد بسیار زیادی connector وجود دارد که بسته به استفاده ما میتوانیم از آنها کمک بگیریم به عنوان مثال اگر بخواهیم داده را از postgress به کافکا منتقل کنیم کافی است connector آن را که پیاده‌سازی شده است استفاده کنیم. حال هنگامی که به این connector ها یک سری کانفیگ اضافه میکنیم تبدیل به task می‌شوند و این task به worker های موجود در کافکا کانکت داده می‌شوند تا اجرا شوند. حال ممکن است در یک کافکا کانکت چند worker موجود باشد که به آن kafka connect cluster و یا ممکن است یک worker موجود باشد که به آن standone گفته می‌شود. در ادامه به بررسی kafka connect cluster می‌پردازیم.


## kafka connect cluster
<img src="images\img10.png" alt="img10"> 
<br/>

 مطابق شکل فرض کنید تعدادی connector و هر connector تعدادی تسک داشته باشد. حال اگر یکی از worker ها قطع شود، rebalance اتفاق می‌افتد یعنی تسک‌های آن به worker های فعال انتقال پیدا می‌کند و به کار خود ادامه می‌دهند. بنابراین اگر از standone استفاده کنیم در صورت قطع شدن worker تسک های ما از بین خواهد رفت.

 تحقیق به پایان رسید و در این تحقیق سعی شد به مفاهیم اولیه موجود در کافکا پرداخته شود تا در صورت نیاز در کار خود از آن استفاده کنیم.